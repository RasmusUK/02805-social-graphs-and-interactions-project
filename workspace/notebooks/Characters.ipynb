{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import bz2file as bz2\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "import statistics as stats\n",
    "import pickle\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "import matplotlib.pyplot as plt\n",
    "import community as community_louvain\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from fa2_modified import ForceAtlas2\n",
    "import matplotlib.colors as mcolors\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseUrl = \"https://gameofthronesfanon.fandom.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(title, data):\n",
    "    with bz2.BZ2File(f\"{title}.pbz2\", \"w\") as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(title):\n",
    "    with bz2.BZ2File(f\"{title}.pbz2\", \"r\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(content, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all urls for the characters\n",
    "urls = []\n",
    "for char in [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]:\n",
    "     url = f\"{baseUrl}wiki/Category:Characters?from={char}\"\n",
    "     urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all characters from the Game of Thrones Fanon Wiki\n",
    "if not os.path.exists('../data/all_characters.html'):   \n",
    "    all_content = \"\"\n",
    "    for url in urls:\n",
    "        content = fetch_page(url)\n",
    "        if content:\n",
    "            all_content += content\n",
    "        else:\n",
    "            print(f\"Failed to fetch {url}\")\n",
    "\n",
    "    save_to_file(all_content, '../data/all_characters.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiographicalInfo:\n",
    "    def __init__(self, name, birth_year, birth_place):\n",
    "        self.name = name\n",
    "        self.birth_year = birth_year\n",
    "        self.birth_place = birth_place\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.name} was born in {self.birth_place} in {self.birth_year}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoliticalInfo:\n",
    "    def __init__(self, houses, titles):\n",
    "        self.houses = houses\n",
    "        self.titles = titles\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.titles} of {self.houses}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonalInfo:\n",
    "    def __init__(self, aka, culture, religon, father, mother, spouses, issues, siblings):\n",
    "        self.aka = aka\n",
    "        self.culture = culture\n",
    "        self.religon = religon\n",
    "        self.father = father\n",
    "        self.mother = mother\n",
    "        self.spouses = spouses\n",
    "        self.issues = issues\n",
    "        self.siblings = siblings\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.aka} {self.culture} {self.religon} {self.father} {self.mother} {self.spouses} {self.issues} {self.siblings}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Character:\n",
    "    def __init__(self, name, url, html, text):\n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.html = html\n",
    "        self.text = text\n",
    "        self.references = []\n",
    "        self.biographical_info = None\n",
    "        self.personal_info = None\n",
    "        self.political_info = None\n",
    "        self.sentiment = None\n",
    "        self.tfidf = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Character(name={self.name}, url={self.url})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    content = fetch_page(url)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_character(name, url):\n",
    "    text = get_text(url)\n",
    "    html = get_html(url)\n",
    "    character = Character(name, url, html, text)\n",
    "    return character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_characters_from_matches(matches):\n",
    "    skip = [\"Category:\", \"User:\"]\n",
    "    characters = []\n",
    "    for href, title in matches:\n",
    "        if any(s in title for s in skip):\n",
    "            continue\n",
    "        try:\n",
    "            character = create_character(title, baseUrl + href)\n",
    "            characters.append(character)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_character_matches_of_html():\n",
    "    with open('../data/all_characters.html', 'r', encoding='utf-8') as file:\n",
    "        all_characters_html = file.read()\n",
    "        pattern = r'<a\\s+href=\"([^\"]+)\"\\s+title=\"([^\"]+)\"'\n",
    "        matches = re.findall(pattern, all_characters_html)\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all characters from the html file and add the text and raw html to the character\n",
    "path = '../data/characters_1'\n",
    "characters = []\n",
    "if os.path.exists(f\"{path}.pbz2\"):\n",
    "    characters = load(path)\n",
    "else:    \n",
    "    matches = get_all_character_matches_of_html()\n",
    "    characters = get_characters_from_matches(matches)\n",
    "    save(path, characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add references to the characters\n",
    "pattern = r'<a\\s+href=\"([^\"]+)\"'\n",
    "all_character_urls = [character.url for character in characters]\n",
    "for character in characters:\n",
    "    matches = re.findall(pattern, character.html)\n",
    "    for href in matches:\n",
    "        url = baseUrl + href\n",
    "        if url in all_character_urls and url != character.url:\n",
    "            reference = [c for c in characters if c.url == url][0]\n",
    "            character.references.append(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterAttribute:\n",
    "    def __init__(self, data_source_title, texts):\n",
    "        self.data_source_title = data_source_title\n",
    "        self.texts = texts\n",
    "        self.hrefs = []\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.data_source_title} {self.texts} {self.hrefs}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_by_data_source(character, data_source_title, tag):\n",
    "    soup = BeautifulSoup(character.html, 'html.parser')\n",
    "    result = soup.find(attrs={\"data-source\": data_source_title})\n",
    "    if result:\n",
    "        if tag is None:\n",
    "            results = result\n",
    "        else:\n",
    "            results = result.findAll(tag)\n",
    "        texts = [result.text for result in results]\n",
    "        characterAttribute = CharacterAttribute(data_source_title, texts)\n",
    "        if tag == \"a\":\n",
    "            hrefs = [result['href'] for result in results]\n",
    "            characterAttribute.hrefs = hrefs\n",
    "        return characterAttribute\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(character):\n",
    "    return get_by_data_source(character, \"Title\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_birth_year(character):\n",
    "    return get_by_data_source(character, \"Birth\", \"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_birth_place(character):\n",
    "    return get_by_data_source(character, \"Birth\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles(character):\n",
    "    return get_by_data_source(character, \"Titles\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_houses(character):\n",
    "    return get_by_data_source(character, \"House\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AKA(character):\n",
    "    return get_by_data_source(character, \"AKA\", \"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_culture(character):\n",
    "    return get_by_data_source(character, \"Culture\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_religion(character):\n",
    "    return get_by_data_source(character, \"Religion\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_father(character):\n",
    "    return get_by_data_source(character, \"Father\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mother(character):\n",
    "    return get_by_data_source(character, \"Mother\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spouses(character):\n",
    "    return get_by_data_source(character, \"Spouse\", \"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_issues(character):\n",
    "    return get_by_data_source(character, \"Issue\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siblings(character):\n",
    "    return get_by_data_source(character, \"Siblings\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_character_bibliographical_info(character):\n",
    "    name = get_name(character)\n",
    "    birth_place = get_birth_place(character)\n",
    "    birth_year = get_birth_year(character)\n",
    "    return BiographicalInfo(name, birth_year, birth_place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_political_info(character):\n",
    "    houses = get_houses(character)\n",
    "    titles = get_titles(character)\n",
    "    return PoliticalInfo(houses, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_personal_info(character):\n",
    "    aka = get_AKA(character)\n",
    "    culture = get_culture(character)\n",
    "    religion = get_religion(character)\n",
    "    father = get_father(character)\n",
    "    mother = get_mother(character)\n",
    "    spouses = get_spouses(character)\n",
    "    issues = get_issues(character)\n",
    "    siblings = get_siblings(character)\n",
    "    return PersonalInfo(aka, culture, religion, father, mother, spouses, issues, siblings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add attributes to the characters\n",
    "path = '../data/characters_2'\n",
    "if os.path.exists(f\"{path}.pbz2\"):\n",
    "    characters = load(path)\n",
    "else:   \n",
    "    for character in characters:\n",
    "        character.biographical_info = get_character_bibliographical_info(character)\n",
    "        character.political_info = get_political_info(character)\n",
    "        character.personal_info = get_personal_info(character) \n",
    "    save(path, characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/word_happines\"\n",
    "if not os.path.exists(f\"{path}.pbz2\"):\n",
    "    url = \"https://hedonometer.org/api/v1/words/?format=json&wordlist__title=labMT-en-v2\"\n",
    "\n",
    "    limit = 1000 \n",
    "    offset = 0 \n",
    "\n",
    "    word_happiness_dict = {}\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(url, params={\"limit\": limit, \"offset\": offset})\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            for entry in data[\"objects\"]:\n",
    "                word_happiness_dict[entry[\"word\"]] = entry[\"happs\"]\n",
    "            \n",
    "            if data[\"meta\"][\"next\"] is None:\n",
    "                break  \n",
    "            \n",
    "            offset += limit\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
    "            break\n",
    "    \n",
    "    save(path, word_happiness_dict)\n",
    "else:\n",
    "    word_happiness_dict = load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_for_sentiment(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentiment(tokens):\n",
    "    tokens = [token for token in tokens if token in word_happiness_dict]\n",
    "    return sum(word_happiness_dict[token] for token in tokens) / len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentiment_to_characters():\n",
    "    for character in characters:\n",
    "        tokens = get_tokens_for_sentiment(character.text)\n",
    "        sentiment = calculate_sentiment(tokens)\n",
    "        character.sentiment = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_for_tfidf(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_dict(characters):\n",
    "    tf_dict = {}\n",
    "    for character in characters:\n",
    "        tokens = get_tokens_for_tfidf(character.text)\n",
    "        tf_dict_inner = {}\n",
    "        for token in tokens:\n",
    "            if token not in tf_dict_inner:\n",
    "                tf_dict_inner[token] = 1\n",
    "            else:\n",
    "                tf_dict_inner[token] += 1\n",
    "        tf_dict[character] = tf_dict_inner\n",
    "    return tf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf_dict(tf_dict):\n",
    "    token_counts = {}\n",
    "\n",
    "    for _, tf_dict_inner in tf_dict.items():\n",
    "        unique_tokens = set(tf_dict_inner.keys())\n",
    "        for token in unique_tokens:\n",
    "            if token not in token_counts:\n",
    "                token_counts[token] = 1\n",
    "            else:\n",
    "                token_counts[token] += 1\n",
    "\n",
    "    idf_dict = {}\n",
    "    for token, count in token_counts.items():\n",
    "        idf_dict[token] = math.log(len(characters) / count)\n",
    "    \n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tfidf_to_characters(tf_dict, idf_dict):\n",
    "    for character, tf_dict_inner in tf_dict.items():\n",
    "        tfidf_dict_inner = {}\n",
    "        for token, count in tf_dict_inner.items():\n",
    "            tfidf_dict_inner[token] = count * idf_dict[token]\n",
    "        character.tfidf = sorted(tfidf_dict_inner.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/characters_3'\n",
    "if os.path.exists(f\"{path}.pbz2\"):\n",
    "    characters = load(path)\n",
    "else:   \n",
    "    add_sentiment_to_characters()\n",
    "    tf_dict = get_tf_dict(characters)\n",
    "    idf_dict = get_idf_dict(tf_dict)\n",
    "    add_tfidf_to_characters(tf_dict, idf_dict)\n",
    "    save(path, characters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
